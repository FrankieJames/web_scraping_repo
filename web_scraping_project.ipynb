{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "Driver [/Users/frankiejames/.wdm/drivers/chromedriver/mac64_m1/102.0.5005.61/chromedriver] found in cache\n",
      "/var/folders/sf/lnrr_g5s6bd9cf8zjnzr2b6w0000gn/T/ipykernel_49734/859532887.py:27: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.href is https://www.news-medical.net/news/20220622/Deaths-due-to-fungal-infections-during-the-COVID-19-pandemic-in-the-US.aspx & is type <class 'str'>\n",
      "first eleement of self.href_list is https://www.news-medical.net/news/20220622/Wearable-activity-trackers-combined-with-AI-may-aid-in-early-identification-of-COVID-19.aspx & is type <class 'list'> & is length 19\n",
      "Article Data is a <class 'list'> of 9 dictionaries, which is: [{'url_link': ['https://www.news-medical.net/news/20220622/Online-classes-during-school-closures-may-have-helped-protect-adolescents-mental-health.aspx'], 'title': [\"Online classes during school closures may have helped protect adolescents' mental health\"], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['f2585537-1721-4756-aabe-a5407339d326']}, {'url_link': ['https://www.news-medical.net/news/20220622/Study-Glaucoma-diagnosis-not-associated-with-steeper-rates-of-cognitive-decline.aspx'], 'title': ['Study: Glaucoma diagnosis not associated with steeper rates of cognitive decline'], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['e0f59d55-cffa-4ae7-b297-a422aa14810e']}, {'url_link': ['https://www.news-medical.net/news/20220622/Mathematical-model-helps-predict-the-risk-of-COVID-19-transmission-in-a-train-carriage.aspx'], 'title': ['Mathematical model helps predict the risk of COVID-19 transmission in a train carriage'], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['3c796098-aed7-415d-8499-a6e5875a39e2']}, {'url_link': ['https://www.news-medical.net/news/20220622/Quality-of-care-outcomes-for-stroke-patients-in-VAs-health-system-did-not-decline-during-the-COVID-19-pandemic.aspx'], 'title': [\"Quality of care, outcomes for stroke patients in VA's health system did not decline during the COVID-19 pandemic\"], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['3d7811e2-48f9-459b-90ab-3ef02212d695']}, {'url_link': ['https://www.news-medical.net/news/20220622/Olfactory-sensor-can-authenticate-individuals-by-analyzing-their-breath.aspx'], 'title': ['Olfactory sensor can authenticate individuals by analyzing their breath'], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['30ed1dd3-cc87-4405-92dd-08b2dbc8f2c5']}, {'url_link': ['https://www.news-medical.net/news/20220622/New-Brand-Identity-from-KA-Imaging-for-Patented-Dual-Energy-Technology.aspx'], 'title': ['New Brand Identity from KA Imaging for Patented Dual Energy Technology'], 'author': ['KA Imaging'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['45c4206e-4453-4829-b86d-e60046984ff9']}, {'url_link': ['https://www.news-medical.net/news/20220622/Dissociation-may-indicate-a-high-risk-of-worse-mental-health-outcomes-after-trauma.aspx'], 'title': ['Dissociation may indicate a high risk of worse mental health outcomes after trauma'], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['47dfca3a-bb40-448b-ba1d-f8f7ea8d13bb']}, {'url_link': ['https://www.news-medical.net/news/20220622/Using-air-filters-at-home-can-reduce-negative-impacts-of-air-pollution-on-childrens-brain-development.aspx'], 'title': [\"Using air filters at home can reduce negative impacts of air pollution on children's brain development\"], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['f9584a0d-4ef5-4834-a780-95c6630dec0c']}, {'url_link': ['https://www.news-medical.net/news/20220622/Study-finds-racial-and-ethnic-disparities-in-cardiac-rehabilitation-participation-regardless-of-income.aspx'], 'title': ['Study finds racial and ethnic disparities in cardiac rehabilitation participation regardless of income'], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['840c7028-eeb9-422d-9d05-29b3fac57d39']}]\n",
      " \n",
      "List 1 is: {'url_link': ['https://www.news-medical.net/news/20220622/Online-classes-during-school-closures-may-have-helped-protect-adolescents-mental-health.aspx'], 'title': [\"Online classes during school closures may have helped protect adolescents' mental health\"], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['f2585537-1721-4756-aabe-a5407339d326']}\n",
      " \n",
      "List 2 is: {'url_link': ['https://www.news-medical.net/news/20220622/Study-Glaucoma-diagnosis-not-associated-with-steeper-rates-of-cognitive-decline.aspx'], 'title': ['Study: Glaucoma diagnosis not associated with steeper rates of cognitive decline'], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': ['e0f59d55-cffa-4ae7-b297-a422aa14810e']}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/frankiejames/Documents/GitHub/web_scraping_repo/web_scraping_project.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 188>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/frankiejames/Documents/GitHub/web_scraping_repo/web_scraping_project.ipynb#ch0000000?line=191'>192</a>\u001b[0m news_scraper\u001b[39m.\u001b[39mcreate_raw_data_folder()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/frankiejames/Documents/GitHub/web_scraping_repo/web_scraping_project.ipynb#ch0000000?line=192'>193</a>\u001b[0m news_scraper\u001b[39m.\u001b[39mlink_list()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/frankiejames/Documents/GitHub/web_scraping_repo/web_scraping_project.ipynb#ch0000000?line=193'>194</a>\u001b[0m news_scraper\u001b[39m.\u001b[39;49mcreate_folder_for_each_article()\n",
      "\u001b[1;32m/Users/frankiejames/Documents/GitHub/web_scraping_repo/web_scraping_project.ipynb Cell 1'\u001b[0m in \u001b[0;36mNews_Scraper.create_folder_for_each_article\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/frankiejames/Documents/GitHub/web_scraping_repo/web_scraping_project.ipynb#ch0000000?line=142'>143</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(folder_name)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/frankiejames/Documents/GitHub/web_scraping_repo/web_scraping_project.ipynb#ch0000000?line=143'>144</a>\u001b[0m x \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/frankiejames/Documents/GitHub/web_scraping_repo/web_scraping_project.ipynb#ch0000000?line=144'>145</a>\u001b[0m article_dictionary \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49marticle_data[x\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/frankiejames/Documents/GitHub/web_scraping_repo/web_scraping_project.ipynb#ch0000000?line=145'>146</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfolder_name\u001b[39m}\u001b[39;00m\u001b[39m/data.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/frankiejames/Documents/GitHub/web_scraping_repo/web_scraping_project.ipynb#ch0000000?line=146'>147</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(article_dictionary, f)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome \n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "from datetime import datetime, timedelta\n",
    "import os \n",
    "import uuid \n",
    "import json \n",
    "\n",
    "\n",
    "class News_Scraper:\n",
    "\n",
    "    def __init__(self, url) -> None:\n",
    "        # url to be parameter entered in __name__ == \"__main__\"\n",
    "        self.url = url \n",
    "        \n",
    "        #Creates an empty list for links to each article (to be collected from main news page).\n",
    "        self.href_list = []\n",
    "\n",
    "        #Creates a list to store the dictionaries that contain the information about each article.  \n",
    "        self.article_data = []\n",
    "\n",
    "        # Using ChromeDriver / Selenium to open webpage \n",
    "        self.driver = Chrome(ChromeDriverManager().install())\n",
    "        self.driver.get(url)\n",
    "\n",
    "        # Accepts cookies if they are there. If not pass.\n",
    "        try:\n",
    "            click_accept_cookies = self.driver.find_element(By.ID, \"cookie-accept-link-text\")\n",
    "            click_accept_cookies.click()\n",
    "\n",
    "            # Once cookies are accepted. Scroll to the bottom of the initial page.\n",
    "            try:\n",
    "                scroll_to_bottom = self.driver.find_element(By.TAG_NAME, 'body') \n",
    "                scroll_to_bottom.send_keys(Keys.END)\n",
    "            except:\n",
    "                print(\"Didn't scroll to Medical Links\")\n",
    "                pass \n",
    "\n",
    "        except:\n",
    "            print(\"Couldn't accept cookies, or there were none to accept\")\n",
    "            pass \n",
    "        return\n",
    "\n",
    "    \n",
    "    def news_button(self):\n",
    "        \"\"\"\n",
    "        Method to go to the 'news' page where the articles are listed\n",
    "        \"\"\"\n",
    "        # Below no longer working (had been working before 14/05/22 - WHY???)\n",
    "        # try:\n",
    "        #     time.sleep(2)\n",
    "        #     click_news_button = self.driver.find_element(By.LINK_TEXT, \"News\")\n",
    "        #     click_news_button.click()\n",
    "        #     time.sleep(2)\n",
    "        # except:\n",
    "        #     print(\"Didn't click 'News' button\")\n",
    "        #     pass   \n",
    "        \n",
    "        try:\n",
    "            # news_link_container = self.driver.find_element(By.XPATH, '//div[@class=\"col-xs-6 col-sm-3 footer-menu life-sciences-useful-links\"]')\n",
    "            # news_link = self.driver.find_element(By.XPATH, f\"//a[contains (@href, '/life-sciences/news')]\")\n",
    "            # news_link.click \n",
    "            self.driver.get(\"https://www.news-medical.net/medical/news\")\n",
    "        except:\n",
    "            print(\"Didn't click on news link\")\n",
    "            pass\n",
    "\n",
    "\n",
    "    def link_list(self):\n",
    "        \"\"\"\n",
    "        Return a list (href_list) storing the link for each article on the page.\n",
    "        As each article doesn't have a clear unique identifier (i.e. product number). The URL will be the unique identifier \n",
    "        When each linked it opened, extract data (e.g. title, author, date, source, etc) & store this in a dictionary \n",
    "        \"\"\"\n",
    "\n",
    "        container = self.driver.find_element(By.XPATH, '//div[@class=\"posts publishables-list-wrap first-item-larger\"]')        \n",
    "        self.elements = container.find_elements(By.XPATH, \".//div[@class='col-xs-9']/h3/a\")\n",
    "        for element in self.elements:  \n",
    "            self.href = element.get_attribute('href') # this is returnning as the same as url for the news page. NOT the individual hrefs for each article as aimed. WHY????\n",
    "            self.href_list.append(self.href) # This returns a list of all the urls for each article on the news page. \n",
    "        \n",
    "        print(f\"self.href is {self.href} & is type {type(self.href)}\") \n",
    "        print(f\"first eleement of self.href_list is {self.href_list[0]} & is type {type(self.href_list)} & is length {len(self.href_list)}\")\n",
    "\n",
    "        self.href_list_shorten = self.href_list[:10]\n",
    "\n",
    "        for i in range(len(self.href_list_shorten)):\n",
    "            item = str(self.href_list_shorten[i])\n",
    "\n",
    "            self.article_dict= {\n",
    "                \"url_link\": [],\n",
    "                \"title\": [],\n",
    "                \"author\": [],\n",
    "                \"date\": [],\n",
    "                \"source\": [],\n",
    "                \"uuid_ID\": []\n",
    "            }\n",
    "\n",
    "            if (item != str(self.href_list_shorten[0])) and (item != str(self.href_list_shorten[i-1])):\n",
    "\n",
    "                self.driver.get(item)\n",
    "                \n",
    "                self.url_link = item\n",
    "                self.article_dict[\"url_link\"].append(self.url_link)\n",
    "\n",
    "                self.title = self.driver.title\n",
    "                self.article_dict[\"title\"].append(self.title)\n",
    "                \n",
    "                self.author_container = self.driver.find_element(By.CLASS_NAME, \"article-meta-contents\")\n",
    "                self.author_link = self.author_container.find_element(By.XPATH, \".//a[@href]\")\n",
    "                self.author = self.author_link.text\n",
    "                self.article_dict[\"author\"].append(self.author)\n",
    "                \n",
    "                self.date = self.driver.find_element(By.CLASS_NAME, \"article-meta-date\").text\n",
    "                self.article_dict[\"date\"].append(self.date)\n",
    "\n",
    "                self.ID_for_each_article()\n",
    "\n",
    "                self.article_data.append(self.article_dict)\n",
    "            else:\n",
    "                pass\n",
    "        print(f\"Article Data is a {type(self.article_data)} of {len(self.article_data)} dictionaries, which is: {self.article_data}\")\n",
    "        print(\" \")\n",
    "        print(f\"List 1 is: {self.article_data[0]}\")\n",
    "        print(\" \")\n",
    "        print(f\"List 2 is: {self.article_data[1]}\")\n",
    "    \n",
    "\n",
    "    def create_folder_for_each_article(self):\n",
    "        \"\"\" \n",
    "        Create an empty folder for each article in the list.\n",
    "        Will add json file into each to store the data and a image. \n",
    "        Later will change to place all these folders within \"raw_data\"\n",
    "        \"\"\"\n",
    "        x = 1 \n",
    "        for item in self.article_data:\n",
    "            folder_name = f\"article {x}\"\n",
    "            if not os.path.exists(folder_name):\n",
    "                os.makedirs(folder_name)\n",
    "            article_dictionary = self.article_data[x-1]\n",
    "            with open(f\"{folder_name}/data.json\", \"w\") as f:\n",
    "                json.dump(article_dictionary, f)\n",
    "            x += 1\n",
    "            \n",
    "\n",
    "\n",
    "    def ID_for_each_article(self):\n",
    "        \"\"\" \n",
    "        Create a list of uuid for each item in a list (i.e. for each url in the link_list, create a associated uuid\n",
    "        Using version 4 \n",
    "        \"\"\"\n",
    "        # self.article_data[\"uuid\"]\n",
    "        # self.uuid_list = []\n",
    "        link_ID = str(uuid.uuid4())\n",
    "        self.article_dict[\"uuid_ID\"].append(link_ID)\n",
    "        # print(f\"uuid_list is: {self.uuid_list}\")\n",
    "        # return self.uuid_list\n",
    "\n",
    "    def image(self):\n",
    "        \"\"\"\n",
    "        Extract an image from each article \n",
    "        \"\"\"\n",
    "        content_container = self.driver.find_element(By.XPATH, \"//div[@class = 'content']\")\n",
    "        image_container = content_container.find_element(By.XPATH, \"//figure[@class = 'contentImage']/span/img\")\n",
    "        image = image_container.get_attribute(\"src\")\n",
    "\n",
    "\n",
    "    def create_raw_data_folder(self):\n",
    "        \"\"\"\n",
    "        Creates a folder called raw data, this will store a folder for each artile with all it's data. \n",
    "        Before a fodler is created, it will check if one has already been made. \n",
    "        Need to define where this will be stored \n",
    "        Uses os method \n",
    "        \"\"\"\n",
    "\n",
    "        if not os.path.exists('raw_data'):\n",
    "            os.makedirs('raw_data')\n",
    "    \n",
    "    # def create_json_file(self):\n",
    "    #     for i in range(len(self.article_data)):\n",
    "            \n",
    "    \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    news_scraper = News_Scraper('https://www.news-medical.net/')\n",
    "    # news_scraper.scroll_down()\n",
    "    news_scraper.news_button()\n",
    "    news_scraper.create_raw_data_folder()\n",
    "    news_scraper.link_list()\n",
    "    news_scraper.create_folder_for_each_article()\n",
    "    # for i in range(len(news_scraper.article_data)):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eebf51706ff08164fbfc0f7261be8d269ebf4f841796856fd2cb500d849fc298"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('wbs_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
