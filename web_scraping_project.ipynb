{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/102.0.5005.61/chromedriver_mac64_m1.zip\n",
      "Driver has been saved in cache [/Users/frankiejames/.wdm/drivers/chromedriver/mac64_m1/102.0.5005.61]\n",
      "/var/folders/sf/lnrr_g5s6bd9cf8zjnzr2b6w0000gn/T/ipykernel_44247/504836309.py:27: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.href is https://www.news-medical.net/news/20220622/Clinicians-can-help-to-empower-patients-by-encouraging-them-to-vote.aspx & is type <class 'str'>\n",
      "first eleement of self.href_list is https://www.news-medical.net/news/20220622/Dissociation-may-indicate-a-high-risk-of-worse-mental-health-outcomes-after-trauma.aspx & is type <class 'list'> & is length 19\n",
      "Article Data Dictionary is: [{'url_link': ['https://www.news-medical.net/news/20220622/Using-air-filters-at-home-can-reduce-negative-impacts-of-air-pollution-on-childrens-brain-development.aspx'], 'title': [\"Using air filters at home can reduce negative impacts of air pollution on children's brain development\"], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': [UUID('6a6ab452-1fc9-4d0a-964a-4a489e729cb4')]}, {'url_link': ['https://www.news-medical.net/news/20220622/Study-finds-racial-and-ethnic-disparities-in-cardiac-rehabilitation-participation-regardless-of-income.aspx'], 'title': ['Study finds racial and ethnic disparities in cardiac rehabilitation participation regardless of income'], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': [UUID('b387a4d5-334d-4415-88bb-4773b086b5e0')]}, {'url_link': ['https://www.news-medical.net/news/20220622/Automated-barcode-applicator-for-microplates-and-petri-dishes.aspx'], 'title': ['Automated barcode applicator for microplates and Petri dishes'], 'author': ['Porvair Sciences Limited'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': [UUID('0fb6dd63-8520-40ec-8c23-a62f4785adc5')]}, {'url_link': ['https://www.news-medical.net/news/20220622/Scientists-evaluate-JNK-inhibitors-in-treating-moderate-to-severe-COVID-19-patients.aspx'], 'title': ['Scientists evaluate JNK inhibitors in treating moderate to severe COVID-19 patients'], 'author': ['Dr. Sanchari Sinha Dutta, Ph.D.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': [UUID('4a99008b-8590-424c-b30d-71eb4485fa6a')]}, {'url_link': ['https://www.news-medical.net/news/20220622/FUJIFILM-Corporation-Commit-Themselves-to-Digital-Pathology.aspx'], 'title': ['FUJIFILM Corporation Commit Themselves to Digital Pathology'], 'author': ['FUJIFILM Corporation'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': [UUID('4187c53f-0281-4701-8de9-ad4a9976bfd9')]}, {'url_link': ['https://www.news-medical.net/news/20220622/INTEGRAe28099s-PIPETBOY-acu-2-pipette-controller-takes-a-deep-dive-into-cellular-physics.aspx'], 'title': ['INTEGRAâ€™s PIPETBOY acu 2 pipette controller'], 'author': ['INTEGRA Biosciences'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': [UUID('54a6c072-4704-4e2f-91f6-541688e047a3')]}, {'url_link': ['https://www.news-medical.net/news/20220622/The-role-of-smartphone-apps-during-the-COVID-19-pandemic.aspx'], 'title': ['The role of smartphone apps during the COVID-19 pandemic'], 'author': ['Bhavana Kunkalikar'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': [UUID('d913e930-9085-424b-a170-72e4281c2571')]}, {'url_link': ['https://www.news-medical.net/news/20220622/New-weight-loss-treatment-is-marked-by-heavy-marketing-and-modest-results.aspx'], 'title': ['New weight loss treatment is marked by heavy marketing and modest results'], 'author': ['Emily Henderson, B.Sc.'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': [UUID('8c33273c-9466-4822-9960-5a451d79bf2b')]}, {'url_link': ['https://www.news-medical.net/news/20220622/The-possible-immune-mediated-mechanisms-causing-CNS-alterations-during-and-post-acute-SARS-CoV-2-infection.aspx'], 'title': ['The possible immune-mediated mechanisms causing CNS alterations during and post-acute SARS-CoV-2 infection'], 'author': ['Pooja Toshniwal Paharia'], 'date': ['Jun 22 2022'], 'source': [], 'uuid_ID': [UUID('51430058-9b77-4095-8b1f-e34013efff45')]}] & has  <class 'list'> & has 9\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome \n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "from datetime import datetime, timedelta\n",
    "import os \n",
    "import uuid \n",
    "import json \n",
    "\n",
    "\n",
    "class News_Scraper:\n",
    "\n",
    "    def __init__(self, url) -> None:\n",
    "        # url to be parameter entered in __name__ == \"__main__\"\n",
    "        self.url = url \n",
    "        \n",
    "        #Creates an empty list for links to each article (to be collected from main news page).\n",
    "        self.href_list = []\n",
    "\n",
    "        #Creates a list to store the dictionaries that contain the information about each article.  \n",
    "        self.article_data = []\n",
    "\n",
    "        # Using ChromeDriver / Selenium to open webpage \n",
    "        self.driver = Chrome(ChromeDriverManager().install())\n",
    "        self.driver.get(url)\n",
    "\n",
    "        # Accepts cookies if they are there. If not pass.\n",
    "        try:\n",
    "            click_accept_cookies = self.driver.find_element(By.ID, \"cookie-accept-link-text\")\n",
    "            click_accept_cookies.click()\n",
    "\n",
    "            # Once cookies are accepted. Scroll to the bottom of the initial page.\n",
    "            try:\n",
    "                scroll_to_bottom = self.driver.find_element(By.TAG_NAME, 'body') \n",
    "                scroll_to_bottom.send_keys(Keys.END)\n",
    "            except:\n",
    "                print(\"Didn't scroll to Medical Links\")\n",
    "                pass \n",
    "\n",
    "        except:\n",
    "            print(\"Couldn't accept cookies, or there were none to accept\")\n",
    "            pass \n",
    "        return\n",
    "\n",
    "    \n",
    "    def news_button(self):\n",
    "        \"\"\"\n",
    "        Method to go to the 'news' page where the articles are listed\n",
    "        \"\"\"\n",
    "        # Below no longer working (had been working before 14/05/22 - WHY???)\n",
    "        # try:\n",
    "        #     time.sleep(2)\n",
    "        #     click_news_button = self.driver.find_element(By.LINK_TEXT, \"News\")\n",
    "        #     click_news_button.click()\n",
    "        #     time.sleep(2)\n",
    "        # except:\n",
    "        #     print(\"Didn't click 'News' button\")\n",
    "        #     pass   \n",
    "        \n",
    "        try:\n",
    "            # news_link_container = self.driver.find_element(By.XPATH, '//div[@class=\"col-xs-6 col-sm-3 footer-menu life-sciences-useful-links\"]')\n",
    "            # news_link = self.driver.find_element(By.XPATH, f\"//a[contains (@href, '/life-sciences/news')]\")\n",
    "            # news_link.click \n",
    "            self.driver.get(\"https://www.news-medical.net/medical/news\")\n",
    "        except:\n",
    "            print(\"Didn't click on news link\")\n",
    "            pass\n",
    "\n",
    "\n",
    "    def link_list(self):\n",
    "        \"\"\"\n",
    "        Return a list (href_list) storing the link for each article on the page.\n",
    "        As each article doesn't have a clear unique identifier (i.e. product number). The URL will be the unique identifier \n",
    "        When each linked it opened, extract data (e.g. title, author, date, source, etc) & store this in a dictionary \n",
    "        \"\"\"\n",
    "\n",
    "        container = self.driver.find_element(By.XPATH, '//div[@class=\"posts publishables-list-wrap first-item-larger\"]')        \n",
    "        self.elements = container.find_elements(By.XPATH, \".//div[@class='col-xs-9']/h3/a\")\n",
    "        for element in self.elements:  \n",
    "            self.href = element.get_attribute('href') # this is returnning as the same as url for the news page. NOT the individual hrefs for each article as aimed. WHY????\n",
    "            self.href_list.append(self.href) # This returns a list of all the urls for each article on the news page. \n",
    "        \n",
    "        print(f\"self.href is {self.href} & is type {type(self.href)}\") \n",
    "        print(f\"first eleement of self.href_list is {self.href_list[0]} & is type {type(self.href_list)} & is length {len(self.href_list)}\")\n",
    "\n",
    "        self.href_list_shorten = self.href_list[:10]\n",
    "\n",
    "        for i in range(len(self.href_list_shorten)):\n",
    "            item = str(self.href_list_shorten[i])\n",
    "\n",
    "            self.article_dict= {\n",
    "                \"url_link\": [],\n",
    "                \"title\": [],\n",
    "                \"author\": [],\n",
    "                \"date\": [],\n",
    "                \"source\": [],\n",
    "                \"uuid_ID\": []\n",
    "            }\n",
    "\n",
    "            if (item != str(self.href_list_shorten[0])) and (item != str(self.href_list_shorten[i-1])):\n",
    "\n",
    "                self.driver.get(item)\n",
    "                \n",
    "                self.url_link = item\n",
    "                self.article_dict[\"url_link\"].append(self.url_link)\n",
    "\n",
    "                self.title = self.driver.title\n",
    "                self.article_dict[\"title\"].append(self.title)\n",
    "                \n",
    "                self.author_container = self.driver.find_element(By.CLASS_NAME, \"article-meta-contents\")\n",
    "                self.author_link = self.author_container.find_element(By.XPATH, \".//a[@href]\")\n",
    "                self.author = self.author_link.text\n",
    "                self.article_dict[\"author\"].append(self.author)\n",
    "                \n",
    "                self.date = self.driver.find_element(By.CLASS_NAME, \"article-meta-date\").text\n",
    "                self.article_dict[\"date\"].append(self.date)\n",
    "\n",
    "                self.ID_for_each_article()\n",
    "\n",
    "                self.article_data.append(self.article_dict)\n",
    "            else:\n",
    "                pass\n",
    "        print(f\"Article Data Dictionary is: {self.article_data} & has  {type(self.article_data)} & has {len(self.article_data)}\")\n",
    "\n",
    "    def ID_for_each_article(self):\n",
    "        \"\"\" \n",
    "        Create a list of uuid for each item in a list (i.e. for each url in the link_list, create a associated uuid\n",
    "        Using version 4 \n",
    "        \"\"\"\n",
    "        # self.article_data[\"uuid\"]\n",
    "        # self.uuid_list = []\n",
    "        link_ID = uuid.uuid4()\n",
    "        self.article_dict[\"uuid_ID\"].append(link_ID)\n",
    "        # print(f\"uuid_list is: {self.uuid_list}\")\n",
    "        # return self.uuid_list\n",
    "\n",
    "    def image(self):\n",
    "        \"\"\"\n",
    "        Extract an image from each article \n",
    "        \"\"\"\n",
    "        content_container = self.driver.find_element(By.XPATH, \"//div[@class = 'content']\")\n",
    "        image_container = content_container.find_element(By.XPATH, \"//figure[@class = 'contentImage']/span/img\")\n",
    "        image = image_container.get_attribute(\"src\")\n",
    "\n",
    "\n",
    "    def create_raw_data_folder(self):\n",
    "        \"\"\"\n",
    "        Creates a folder called raw data, this will store a folder for each artile with all it's data. \n",
    "        Before a fodler is created, it will check if one has already been made. \n",
    "        Need to define where this will be stored \n",
    "        Uses os method \n",
    "        \"\"\"\n",
    "\n",
    "        if not os.path.exists('raw_data'):\n",
    "            os.makedirs('raw_data')\n",
    "    \n",
    "    \n",
    "    def create_folder(self, parent_dir, dir):\n",
    "        if not os.path.exists(parent_dir, dir):\n",
    "            os.makedirs(parent_dir, dir)\n",
    "\n",
    "    # def create_article_folder(self):\n",
    "    #     \"\"\"\n",
    "    #     Creates a folder for each article, to place the data we have collected. \n",
    "    #     These folders will be stored within raw_data folder \n",
    "    #     \"\"\"\n",
    "    #     for i in range(len(self.article_data)):\n",
    "    #         folder_name = str(self.article_dict[i][\"url_link\"])\n",
    "    #         self.create_folder(f\"raw_data/{folder_name}\")\n",
    "    #         print(f\"folder name is: {folder_name}\")\n",
    "    #     # def store_data_locally(self):\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    news_scraper = News_Scraper('https://www.news-medical.net/')\n",
    "    # news_scraper.scroll_down()\n",
    "    news_scraper.news_button()\n",
    "    news_scraper.link_list()\n",
    "    news_scraper.create_raw_data_folder()\n",
    "    # for i in range(len(news_scraper.article_data)):\n",
    "        \n",
    "    # news_scraper.create_article_folder()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eebf51706ff08164fbfc0f7261be8d269ebf4f841796856fd2cb500d849fc298"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('wbs_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
