{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome \n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "from datetime import datetime, timedelta\n",
    "import os \n",
    "import uuid \n",
    "import json \n",
    "\n",
    "\n",
    "class News_Scraper:\n",
    "\n",
    "    def __init__(self, url) -> None:\n",
    "        # url to be parameter entered in __name__ == \"__main__\"\n",
    "        self.url = url \n",
    "        \n",
    "        #Creates an empty list for links to each article (to be collected from main news page).\n",
    "        self.href_list = []\n",
    "        \n",
    "        #Creates a dictionary of empty lists to store information about each article. \n",
    "        self.article_data = {\n",
    "            \"title\": [],\n",
    "            \"author\": [],\n",
    "            \"date\": [],\n",
    "            \"source\": [],\n",
    "            #\"uuid\": []\n",
    "        }\n",
    "\n",
    "        self.store_info = \"./raw_data\"\n",
    "\n",
    "        # Using ChromeDriver / Selenium to open webpage \n",
    "        self.driver = Chrome(ChromeDriverManager().install())\n",
    "        self.driver.get(url)\n",
    "        # time.sleep(2)\n",
    "\n",
    "        # Accepts cookies if they are there. If not pass.\n",
    "        try:\n",
    "            click_accept_cookies = self.driver.find_element(By.ID, \"cookie-accept-link-text\")\n",
    "            click_accept_cookies.click()\n",
    "            # time.sleep(2)\n",
    "\n",
    "            # Once cookies are accepted. Scroll to the bottom of the initial page.\n",
    "            try:\n",
    "                scroll_to_bottom = self.driver.find_element(By.TAG_NAME, 'body') \n",
    "                scroll_to_bottom.send_keys(Keys.END)\n",
    "                # time.sleep(2)\n",
    "            except:\n",
    "                print(\"Didn't scroll to Medical Links\")\n",
    "                pass \n",
    "\n",
    "        except:\n",
    "            print(\"Couldn't accept cookies, or there were none to accept\")\n",
    "            pass \n",
    "        return\n",
    "\n",
    "    \n",
    "    def news_button(self):\n",
    "        \"\"\"\n",
    "        Method to go to the 'news' page where the articles are listed\n",
    "        \"\"\"\n",
    "        # Below no longer working (had been working before 14/05/22 - WHY???)\n",
    "        # try:\n",
    "        #     time.sleep(2)\n",
    "        #     click_news_button = self.driver.find_element(By.LINK_TEXT, \"News\")\n",
    "        #     click_news_button.click()\n",
    "        #     time.sleep(2)\n",
    "        # except:\n",
    "        #     print(\"Didn't click 'News' button\")\n",
    "        #     pass   \n",
    "        \n",
    "        try:\n",
    "            # news_link_container = self.driver.find_element(By.XPATH, '//div[@class=\"col-xs-6 col-sm-3 footer-menu life-sciences-useful-links\"]')\n",
    "            # news_link = self.driver.find_element(By.XPATH, f\"//a[contains (@href, '/life-sciences/news')]\")\n",
    "            # news_link.click \n",
    "            self.driver.get(\"https://www.news-medical.net/medical/news\")\n",
    "        except:\n",
    "            print(\"Didn't click on news link\")\n",
    "            pass\n",
    "\n",
    "\n",
    "    def link_list(self):\n",
    "        \"\"\"\n",
    "        Return a list storing the link for each article on the page.\n",
    "        This gives a list everytime, and the next list just adds on the previous \n",
    "        As each article doesn't have a clear unique identifier (i.e. product number). The URL will be the unique identifier \n",
    "        \"\"\"\n",
    "        container = self.driver.find_element(By.XPATH, '//div[@class=\"posts publishables-list-wrap first-item-larger\"]')\n",
    "        self.elements = container.find_elements(By.XPATH, \".//a[@href]\")\n",
    "        for element in self.elements:  \n",
    "            self.href = element.get_attribute('href') # this is returnning as the same as url for the news page. NOT the individual hrefs for each article as aimed. WHY????\n",
    "            self.href_list.append(self.href) # This returns a list of all the urls for each article on the news page. \n",
    "        \n",
    "        print(f\"self.href is {self.href} & is type {type(self.href)}\") \n",
    "        print(f\"first eleement of self.href_list is {self.href_list[0]} & is type {type(self.href_list)} & is length {len(self.href_list)}\")\n",
    "        \n",
    "        self.title_list = []\n",
    "        self.author_list = []\n",
    "        self.date_list = []\n",
    "        self.source_list = []\n",
    "        self.href_list_shorten = self.href_list[:20]\n",
    "\n",
    "\n",
    "        # for index, element in enumerate(self.href_list_shorten):\n",
    "        #     if (index + 1 < len(self.href_list_shorten) and index - 1 >= 0):\n",
    "        #         prev_element = str(self.href_list_shorten[index - 1])\n",
    "        #         curr_element = str(element)\n",
    "        #         next_element = str(self.href_list_shorten[index + 1])\n",
    "        #         print(f\"Previous is: {prev_element}, current is {curr_element}, and next is {next_element}\")\n",
    "            \n",
    "\n",
    "        for i in range(len(self.href_list_shorten)):\n",
    "\n",
    "            item = str(self.href_list_shorten[i])\n",
    "\n",
    "            if i >= 1:\n",
    "                \n",
    "                if (item != str(self.href_list_shorten[0])) and (item != str(self.href_list_shorten[i-1])):\n",
    "                    self.driver.get(item)\n",
    "                    self.title = self.driver.title\n",
    "                    self.title_list.append(self.title)\n",
    "                    \n",
    "                    self.author_container = self.driver.find_element(By.CLASS_NAME, \"article-meta-contents\")\n",
    "                    self.author_link = self.author_container.find_element(By.XPATH, \".//a[@href]\")\n",
    "                    self.author = self.author_link.text\n",
    "                    self.author_list.append(self.author)\n",
    "                    \n",
    "                    self.date = self.driver.find_element(By.CLASS_NAME, \"article-meta-date\").text\n",
    "                    self.date_list.append(self.date)\n",
    "                    \n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        print(f\"Title_list is: {self.title_list} & has type {type(self.title_list)} and length {len(self.title_list)})\")\n",
    "        print(f\"Author list is {self.author_list} & has type {type(self.author_list)} and length {len(self.author_list)})\")\n",
    "        print(f\"Date list is {self.date_list} & has type {type(self.date_list)} and length {len(self.date_list)})\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    news_scraper = News_Scraper('https://www.news-medical.net/')\n",
    "    # news_scraper.scroll_down()\n",
    "    news_scraper.news_button()\n",
    "    news_scraper.link_list()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eebf51706ff08164fbfc0f7261be8d269ebf4f841796856fd2cb500d849fc298"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('wbs_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
