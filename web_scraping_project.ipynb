{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "Driver [/Users/frankiejames/.wdm/drivers/chromedriver/mac64_m1/102.0.5005.61/chromedriver] found in cache\n",
      "/var/folders/sf/lnrr_g5s6bd9cf8zjnzr2b6w0000gn/T/ipykernel_12022/3430883776.py:35: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.href is https://www.news-medical.net/medical/news?page=2 & is type <class 'str'>\n",
      "first eleement of self.href_list is https://www.news-medical.net/news/20220608/Einstein-researchers-receive-2435-million-NIH-grant-to-study-the-effects-of-SARS-CoV-2-on-the-brain.aspx & is type <class 'list'> & is length 45\n",
      "Title_list is: ['Black, Hispanic patients with advanced liver cancer have lower chance of receiving immunotherapy', 'Vegan diet leads to decreased weight and improved insulin sensitivity', 'Individuals who had COVID‐19 report more cognitive failures at work, study shows', \"Fathers’ depression in economically struggling families may be damaging to the couple's relationship\", 'Childhood cancer survivors 80% more likely to be undertreated for cardiovascular risk factors', 'Early identification and treatment can reduce financial costs associated with spinal muscular atrophy', 'Women with PCOS more likely to be diagnosed with additional medical conditions, study shows', 'Walking for exercise could help people with knee osteoarthritis to prevent frequent knee pain', 'Ayurvedic medicine is effective in blood sugar control in patients with type 2 diabetes, study finds'] & has type <class 'list'> and length 9)\n",
      "Author list is ['Emily Henderson, B.Sc.', 'Emily Henderson, B.Sc.', 'Emily Henderson, B.Sc.', 'Emily Henderson, B.Sc.', 'Emily Henderson, B.Sc.', 'Emily Henderson, B.Sc.', 'Emily Henderson, B.Sc.', 'Emily Henderson, B.Sc.', 'Emily Henderson, B.Sc.'] & has type <class 'list'> and length 9)\n",
      "Date list is ['Jun 8 2022', 'Jun 8 2022', 'Jun 8 2022', 'Jun 8 2022', 'Jun 8 2022', 'Jun 8 2022', 'Jun 8 2022', 'Jun 8 2022', 'Jun 8 2022'] & has type <class 'list'> and length 9)\n",
      "uuid_list is: [UUID('7e9ebfd2-9117-45c4-9ab3-6f15c50e0172')] & has type <class 'list'> and length 1\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome \n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "from datetime import datetime, timedelta\n",
    "import os \n",
    "import uuid \n",
    "import json \n",
    "\n",
    "\n",
    "class News_Scraper:\n",
    "\n",
    "    def __init__(self, url) -> None:\n",
    "        # url to be parameter entered in __name__ == \"__main__\"\n",
    "        self.url = url \n",
    "        \n",
    "        #Creates an empty list for links to each article (to be collected from main news page).\n",
    "        self.href_list = []\n",
    "        \n",
    "        #Creates a dictionary of empty lists to store information about each article. \n",
    "        self.article_data = {\n",
    "            \"title\": [],\n",
    "            \"author\": [],\n",
    "            \"date\": [],\n",
    "            \"source\": [],\n",
    "            #\"uuid\": []\n",
    "        }\n",
    "\n",
    "        self.store_info = \"./raw_data\"\n",
    "\n",
    "        # Using ChromeDriver / Selenium to open webpage \n",
    "        self.driver = Chrome(ChromeDriverManager().install())\n",
    "        self.driver.get(url)\n",
    "        # time.sleep(2)\n",
    "\n",
    "        # Accepts cookies if they are there. If not pass.\n",
    "        try:\n",
    "            click_accept_cookies = self.driver.find_element(By.ID, \"cookie-accept-link-text\")\n",
    "            click_accept_cookies.click()\n",
    "            # time.sleep(2)\n",
    "\n",
    "            # Once cookies are accepted. Scroll to the bottom of the initial page.\n",
    "            try:\n",
    "                scroll_to_bottom = self.driver.find_element(By.TAG_NAME, 'body') \n",
    "                scroll_to_bottom.send_keys(Keys.END)\n",
    "                # time.sleep(2)\n",
    "            except:\n",
    "                print(\"Didn't scroll to Medical Links\")\n",
    "                pass \n",
    "\n",
    "        except:\n",
    "            print(\"Couldn't accept cookies, or there were none to accept\")\n",
    "            pass \n",
    "        return\n",
    "\n",
    "    \n",
    "    def news_button(self):\n",
    "        \"\"\"\n",
    "        Method to go to the 'news' page where the articles are listed\n",
    "        \"\"\"\n",
    "        # Below no longer working (had been working before 14/05/22 - WHY???)\n",
    "        # try:\n",
    "        #     time.sleep(2)\n",
    "        #     click_news_button = self.driver.find_element(By.LINK_TEXT, \"News\")\n",
    "        #     click_news_button.click()\n",
    "        #     time.sleep(2)\n",
    "        # except:\n",
    "        #     print(\"Didn't click 'News' button\")\n",
    "        #     pass   \n",
    "        \n",
    "        try:\n",
    "            # news_link_container = self.driver.find_element(By.XPATH, '//div[@class=\"col-xs-6 col-sm-3 footer-menu life-sciences-useful-links\"]')\n",
    "            # news_link = self.driver.find_element(By.XPATH, f\"//a[contains (@href, '/life-sciences/news')]\")\n",
    "            # news_link.click \n",
    "            self.driver.get(\"https://www.news-medical.net/medical/news\")\n",
    "        except:\n",
    "            print(\"Didn't click on news link\")\n",
    "            pass\n",
    "\n",
    "\n",
    "    def link_list(self):\n",
    "        \"\"\"\n",
    "        Return a list storing the link for each article on the page.\n",
    "        This gives a list everytime, and the next list just adds on the previous \n",
    "        As each article doesn't have a clear unique identifier (i.e. product number). The URL will be the unique identifier \n",
    "        \"\"\"\n",
    "        container = self.driver.find_element(By.XPATH, '//div[@class=\"posts publishables-list-wrap first-item-larger\"]')\n",
    "        self.elements = container.find_elements(By.XPATH, \".//a[@href]\")\n",
    "        for element in self.elements:  \n",
    "            self.href = element.get_attribute('href') # this is returnning as the same as url for the news page. NOT the individual hrefs for each article as aimed. WHY????\n",
    "            self.href_list.append(self.href) # This returns a list of all the urls for each article on the news page. \n",
    "        \n",
    "        print(f\"self.href is {self.href} & is type {type(self.href)}\") \n",
    "        print(f\"first eleement of self.href_list is {self.href_list[0]} & is type {type(self.href_list)} & is length {len(self.href_list)}\")\n",
    "        \n",
    "        self.title_list = []\n",
    "        self.author_list = []\n",
    "        self.date_list = []\n",
    "        self.source_list = []\n",
    "        self.href_list_shorten = self.href_list[:20]\n",
    "        self.uuid_list = []\n",
    "\n",
    "        # link_ID = uuid.uuid4()\n",
    "\n",
    "        # for index, element in enumerate(self.href_list_shorten):\n",
    "        #     if (index + 1 < len(self.href_list_shorten) and index - 1 >= 0):\n",
    "        #         prev_element = str(self.href_list_shorten[index - 1])\n",
    "        #         curr_element = str(element)\n",
    "        #         next_element = str(self.href_list_shorten[index + 1])\n",
    "        #         print(f\"Previous is: {prev_element}, current is {curr_element}, and next is {next_element}\")\n",
    "            \n",
    "\n",
    "        for i in range(len(self.href_list_shorten)):\n",
    "\n",
    "            item = str(self.href_list_shorten[i])\n",
    "\n",
    "            if i >= 1:\n",
    "                \n",
    "                if (item != str(self.href_list_shorten[0])) and (item != str(self.href_list_shorten[i-1])):\n",
    "                    self.driver.get(item)\n",
    "                    self.title = self.driver.title\n",
    "                    self.title_list.append(self.title)\n",
    "                    \n",
    "                    self.author_container = self.driver.find_element(By.CLASS_NAME, \"article-meta-contents\")\n",
    "                    self.author_link = self.author_container.find_element(By.XPATH, \".//a[@href]\")\n",
    "                    self.author = self.author_link.text\n",
    "                    self.author_list.append(self.author)\n",
    "                    \n",
    "                    self.date = self.driver.find_element(By.CLASS_NAME, \"article-meta-date\").text\n",
    "                    self.date_list.append(self.date)\n",
    "\n",
    "                    # self.uuid_list.append(link_ID)\n",
    "                    self.ID_for_each_article()\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        print(f\"Title_list is: {self.title_list} & has type {type(self.title_list)} and length {len(self.title_list)})\")\n",
    "        print(f\"Author list is {self.author_list} & has type {type(self.author_list)} and length {len(self.author_list)})\")\n",
    "        print(f\"Date list is {self.date_list} & has type {type(self.date_list)} and length {len(self.date_list)})\")\n",
    "        print(f\"uuid_list is: {self.uuid_list} & has type {type(self.uuid_list)} and length {len(self.uuid_list)}\")\n",
    "\n",
    "    def ID_for_each_article(self):\n",
    "        \"\"\" \n",
    "        Create a list of uuid for each item in a list (i.e. for each url in the link_list, create a associated uuid\n",
    "        Using version 4 \n",
    "        \"\"\"\n",
    "        # self.article_data[\"uuid\"]\n",
    "        # self.uuid_list = []\n",
    "        link_ID = uuid.uuid4()\n",
    "        self.uuid_list.append(link_ID)\n",
    "        # print(f\"uuid_list is: {self.uuid_list}\")\n",
    "        # return self.uuid_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    news_scraper = News_Scraper('https://www.news-medical.net/')\n",
    "    # news_scraper.scroll_down()\n",
    "    news_scraper.news_button()\n",
    "    news_scraper.link_list()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eebf51706ff08164fbfc0f7261be8d269ebf4f841796856fd2cb500d849fc298"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('wbs_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
